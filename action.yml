name: 'Agentic AppSec Pipeline'
description: 'AI-driven application security analysis for pull requests'

inputs:
  github_token:
    description: 'GitHub token for API access'
    required: true
  mode:
    description: 'shadow (observe only, never blocks) or enforce (can block the PR)'
    required: false
    default: 'shadow'
  ai_api_key:
    description: 'API key for AI provider (OpenAI, Anthropic, etc). Optional â€” without it, uses deterministic fallback.'
    required: false
    default: ''
  ai_model:
    description: 'LLM model ID for LiteLLM (e.g. gpt-4o-mini, anthropic/claude-sonnet-4-5-20250929)'
    required: false
    default: 'gpt-4o-mini'
  command:
    description: 'scan (default) or remediate'
    required: false
    default: 'scan'

outputs:
  decision:
    description: 'Security verdict: allowed, manual_review, or blocked'
  continue_pipeline:
    description: 'true if the pipeline should continue, false if blocked'
  findings_count:
    description: 'Total number of confirmed security findings'
  reason:
    description: 'Human-readable explanation of the decision'
  safety_warnings_count:
    description: 'Number of safety net warnings (dismissed HIGH/CRITICAL)'
  excepted_count:
    description: 'Number of findings auto-excepted by exception memory'

runs:
  using: 'docker'
  image: 'Dockerfile'
  env:
    INPUT_GITHUB_TOKEN: ${{ inputs.github_token }}
    INPUT_MODE: ${{ inputs.mode }}
    INPUT_AI_API_KEY: ${{ inputs.ai_api_key }}
    INPUT_AI_MODEL: ${{ inputs.ai_model }}
    INPUT_COMMAND: ${{ inputs.command }}
